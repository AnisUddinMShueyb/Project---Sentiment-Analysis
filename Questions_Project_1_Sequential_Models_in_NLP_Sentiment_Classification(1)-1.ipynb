{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WXaFSkUu0fzm"
   },
   "source": [
    "![alt text](https://drive.google.com/uc?export=view&id=1UXScsVx_Wni_JuDdB8LeTnM6jsPfIwkW)\n",
    "\n",
    "Proprietary content. Â© Great Learning. All Rights Reserved. Unauthorized use or distribution prohibited."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OudB5by50jlI"
   },
   "source": [
    "# Sentiment Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xT7MKZuMRaCg"
   },
   "source": [
    "### Dataset\n",
    "- Dataset of 50,000 movie reviews from IMDB, labeled by sentiment positive (1) or negative (0)\n",
    "- Reviews have been preprocessed, and each review is encoded as a sequence of word indexes (integers).\n",
    "- For convenience, words are indexed by overall frequency in the dataset, so that for instance the integer \"3\" encodes the 3rd most frequent word in the data. This allows for quick filtering operations such as: \"only consider the top 10,000 most common words, but eliminate the top 20 most common words\".\n",
    "- As a convention, \"0\" does not stand for a specific word, but instead is used to encode any unknown word.\n",
    "\n",
    "Command to import data\n",
    "- `from tensorflow.keras.datasets import imdb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q34-Y3nRKXdO"
   },
   "source": [
    "### Import the data (4 Marks)\n",
    "- Use `imdb.load_data()` method\n",
    "- Get train and test set\n",
    "- Take 10000 most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "-MVsaosZw5aF"
   },
   "outputs": [],
   "source": [
    "# LSTM for sequence classification in the IMDB dataset\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JxfwbrbuKbk2",
    "outputId": "660ab281-3a3b-4648-b6f0-a5d91dd2a4f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The `nb_words` argument in `load_data` has been renamed `num_words`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "top_words = 10000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jP_Yz5T2wb-O",
    "outputId": "26bf3d4c-7bd9-4804-9240-90b1b2382fc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 8255, 2, 349, 2637, 148, 605, 2, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]\n",
      "<class 'list'>\n",
      "189\n"
     ]
    }
   ],
   "source": [
    "print(X_train[1])\n",
    "print(type(X_train[1]))\n",
    "print(len(X_train[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DldivBO4LTbP"
   },
   "source": [
    "### Pad each sentence to be of same length (4 Marks)\n",
    "- Take maximum sequence length as 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "E808XB4tLtic"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "max_review_length = 300\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length,padding='post')\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length,padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JBFFCrybMSXz"
   },
   "source": [
    "### Print shape of features & labels (4 Marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qOcyRtZfMYZd"
   },
   "source": [
    "Number of review, number of words in each review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hdMCUPr7RaCm",
    "outputId": "468a4dbf-a07a-4433-b848-b134ff008504"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 300)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CKXZDIlE1ue9",
    "outputId": "0ce37441-964d-4323-b194-480564c4a0d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 300)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eGVHeKOWyJiG",
    "outputId": "0ba61e13-1d32-46a0-b420-ce5eff960b76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train[0,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MljctLpX2Gbk",
    "outputId": "274156a0-4b1a-4b6a-a096-68f51f06ac90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "print(len(X_test[0,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5cNk5sDvMr3j"
   },
   "source": [
    "Number of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Z00-mYgMoKv",
    "outputId": "e9aca000-583b-44c1-bf32-46088a15e8e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H7f5tPeaMxti",
    "outputId": "2256521a-3ab6-4b91-c856-caebc3f6e3a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zBwudQvF12GC",
    "outputId": "a1d410c6-e008-47c4-e671-a47175b0e2f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NdXPWuOmNEbh"
   },
   "source": [
    "### Print value of any one feature and it's label (4 Marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MGLEdeFmNZfR"
   },
   "source": [
    "Feature value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RKFyMa28zztL",
    "outputId": "c1d59adc-3610-44af-dd3b-c333d7e88897"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1  194 1153  194 8255   78  228    5    6 1463 4369 5012  134   26\n",
      "    4  715    8  118 1634   14  394   20   13  119  954  189  102    5\n",
      "  207  110 3103   21   14   69  188    8   30   23    7    4  249  126\n",
      "   93    4  114    9 2300 1523    5  647    4  116    9   35 8163    4\n",
      "  229    9  340 1322    4  118    9    4  130 4901   19    4 1002    5\n",
      "   89   29  952   46   37    4  455    9   45   43   38 1543 1905  398\n",
      "    4 1649   26 6853    5  163   11 3215    2    4 1153    9  194  775\n",
      "    7 8255    2  349 2637  148  605    2 8003   15  123  125   68    2\n",
      " 6853   15  349  165 4362   98    5    4  228    9   43    2 1157   15\n",
      "  299  120    5  120  174   11  220  175  136   50    9 4373  228 8255\n",
      "    5    2  656  245 2350    5    4 9837  131  152  491   18    2   32\n",
      " 7464 1212   14    9    6  371   78   22  625   64 1382    9    8  168\n",
      "  145   23    4 1690   15   16    4 1355    5   28    6   52  154  462\n",
      "   33   89   78  285   16  145   95    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_85Hqm0Nb1I"
   },
   "source": [
    "Label value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-FoehB5jNd1g",
    "outputId": "3e182d96-ebbd-41ad-9b78-16e32d6f591b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(y_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0cof4LSxNxuv"
   },
   "source": [
    "### Decode the feature value to get original sentence (4 Marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q_oiAyPZOkJD"
   },
   "source": [
    "First, retrieve a dictionary that contains mapping of words to their index in the IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Clsk-yK8OtzD",
    "outputId": "25af4771-90f3-4647-e223-03a812244ca3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the thought solid thought senator do making to is spot nomination assumed while he of jack in where picked as getting on was did hands fact characters to always life thrillers not as me can't in at are br of sure your way of little it strongly random to view of love it so principles of guy it used producer of where it of here icon film of outside to don't all unique some like of direction it if out her imagination below keep of queen he diverse to makes this stretch and of solid it thought begins br senator and budget worthwhile though ok and awaiting for ever better were and diverse for budget look kicked any to of making it out and follows for effects show to show cast this family us scenes more it severe making senator to and finds tv tend to of emerged these thing wants but and an beckinsale cult as it is video do you david see scenery it in few those are of ship for with of wild to one is very work dark they don't do dvd with those them\n",
      "negetive\n"
     ]
    }
   ],
   "source": [
    "#word_index = imdb.get_word_index() # get {word : index}\n",
    "#index_word = {v : k for k,v in word_index.items()} # get {index : word}\n",
    "\n",
    "#index = 1\n",
    "#print(\" \".join([index_word[idx] for idx in X_train[index]]))\n",
    "#print(\"positve\" if y_train[index]==1 else \"negetive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jdj-ukckY1Bu"
   },
   "source": [
    "The above gives us an incoherent decoded review. We must check if the padding has effected the encoded data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NRgOD5S2Uuvd"
   },
   "source": [
    "Now use the dictionary to get the original words from the encodings, for a particular sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zJ504QDORwxj",
    "outputId": "d8e6caa8-736e-4fc6-c676-afc5dfd66e55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " big hair big boobs bad music and a giant safety pin these are the words to best describe this terrible movie i love cheesy horror movies and i've seen hundreds but this had got to be on of the worst ever made the plot is paper thin and ridiculous the acting is an abomination the script is completely laughable the best is the end showdown with the cop and how he worked out who the killer is it's just so damn terribly written the clothes are sickening and funny in equal  the hair is big lots of boobs  men wear those cut  shirts that show off their  sickening that men actually wore them and the music is just  trash that plays over and over again in almost every scene there is trashy music boobs and  taking away bodies and the gym still doesn't close for  all joking aside this is a truly bad film whose only charm is to look back on the disaster that was the 80's and have a good old laugh at how bad everything was back then                                                                                                               \n"
     ]
    }
   ],
   "source": [
    "word_index = imdb.get_word_index()                                    \n",
    "reverse_word_index = dict([(v, k) for (k, v) in word_index.items()])            \n",
    "decoded_review = ' '.join([reverse_word_index.get(i - 3, \"\") for i in X_train[1]])\n",
    "print(decoded_review)\n",
    "#Here we have taken into account the changed caused by preproccessing, namely the padding process. Hence by shifting the reverse index by i - 3 we can get the actual decoded review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WLGABrJoVZe6"
   },
   "source": [
    "Get the sentiment for the above sentence\n",
    "- positive (1)\n",
    "- negative (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XDyQGJT0Ve-a",
    "outputId": "0384bb47-6259-4f0c-a5b9-33db2fc4b6b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negetive\n"
     ]
    }
   ],
   "source": [
    "print(\"positve\" if y_train[1]==1 else \"negetive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BmCjr8miXIWB"
   },
   "source": [
    "### Define model (10 Marks)\n",
    "- Define a Sequential Model\n",
    "- Add Embedding layer\n",
    "  - Embedding layer turns positive integers into dense vectors of fixed size\n",
    "  - `tensorflow.keras` embedding layer doesn't require us to onehot encode our words, instead we have to give each word a unique integer number as an id. For the imdb dataset we've loaded this has already been done, but if this wasn't the case we could use sklearn LabelEncoder.\n",
    "  - Size of the vocabulary will be 10000\n",
    "  - Give dimension of the dense embedding as 100\n",
    "  - Length of input sequences should be 300\n",
    "- Add LSTM layer\n",
    "  - Pass value in `return_sequences` as True\n",
    "- Add a `TimeDistributed` layer with 100 Dense neurons\n",
    "- Add Flatten layer\n",
    "- Add Dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Np5GxT1caFEq",
    "outputId": "de7a5fc0-1a3a-4423-b693-465ea49b1fb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(10000, 100,input_length=300))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2,return_sequences=True))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hc4bknOobDby"
   },
   "source": [
    "### Compile the model (4 Marks)\n",
    "- Use Optimizer as Adam\n",
    "- Use Binary Crossentropy as loss\n",
    "- Use Accuracy as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jw4RJ0CQbwFY",
    "outputId": "3b9e3869-3460-4904-f052-01d99c63e3a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 300, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 1,080,501\n",
      "Trainable params: 1,080,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8sEzwazqbz3T"
   },
   "source": [
    "### Print model summary (4 Marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Hx1yxwlb2Ue",
    "outputId": "c572aaf7-96c6-4bb1-a8b8-b722344ada2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 300, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 1,080,501\n",
      "Trainable params: 1,080,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bmkolKP4b-U6"
   },
   "source": [
    "### Fit the model (4 Marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vRg3KFXLcAkk",
    "outputId": "2b3ad6b4-5525-401b-ecf9-76513ba9a290"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "391/391 [==============================] - 468s 1s/step - loss: 0.6914 - accuracy: 0.5139\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 462s 1s/step - loss: 0.6524 - accuracy: 0.5665\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 454s 1s/step - loss: 0.6175 - accuracy: 0.6542\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 447s 1s/step - loss: 0.5797 - accuracy: 0.6754\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 440s 1s/step - loss: 0.5997 - accuracy: 0.6367\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 436s 1s/step - loss: 0.4922 - accuracy: 0.7676\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 440s 1s/step - loss: 0.4439 - accuracy: 0.7979\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 434s 1s/step - loss: 0.5293 - accuracy: 0.6718\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 436s 1s/step - loss: 0.4208 - accuracy: 0.8268\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 427s 1s/step - loss: 0.3716 - accuracy: 0.8579\n",
      "Accuracy: 81.88%\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=64)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwLl54MXnkEA"
   },
   "source": [
    "### Evaluate model (4 Marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vHnX5nJUX4q-"
   },
   "source": [
    "Performed in above step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h2amr1tJn9Jz"
   },
   "source": [
    "### Predict on one sample (4 Marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wl4idfWR_A8E",
    "outputId": "7b19b1b1-eb8e-4cf3-edca-b505d04947e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 300) for input KerasTensor(type_spec=TensorSpec(shape=(None, 300), dtype=tf.float32, name='embedding_1_input'), name='embedding_1_input', description=\"created by layer 'embedding_1_input'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.76044995],\n",
       "       [0.30541104],\n",
       "       [0.3500576 ],\n",
       "       [0.8459484 ],\n",
       "       [0.52827823],\n",
       "       [0.49234426],\n",
       "       [0.47458044],\n",
       "       [0.07044841],\n",
       "       [0.45184883],\n",
       "       [0.72473234],\n",
       "       [0.55862623],\n",
       "       [0.31303087],\n",
       "       [0.06027576],\n",
       "       [0.36162752],\n",
       "       [0.8572193 ],\n",
       "       [0.12489337],\n",
       "       [0.42671138],\n",
       "       [0.07899644],\n",
       "       [0.44874012],\n",
       "       [0.49388972],\n",
       "       [0.96988374],\n",
       "       [0.36162752],\n",
       "       [0.866654  ],\n",
       "       [0.47458044],\n",
       "       [0.42671138],\n",
       "       [0.14759794],\n",
       "       [0.6105374 ],\n",
       "       [0.89776474],\n",
       "       [0.31303087],\n",
       "       [0.42671138],\n",
       "       [0.42676288],\n",
       "       [0.8315427 ],\n",
       "       [0.33853534],\n",
       "       [0.04437233],\n",
       "       [0.503905  ],\n",
       "       [0.42671138],\n",
       "       [0.8354886 ],\n",
       "       [0.9576781 ],\n",
       "       [0.8572193 ],\n",
       "       [0.834519  ],\n",
       "       [0.52525795],\n",
       "       [0.42671138],\n",
       "       [0.3500576 ],\n",
       "       [0.9495769 ],\n",
       "       [0.35417023],\n",
       "       [0.52827823],\n",
       "       [0.8491449 ],\n",
       "       [0.9617277 ],\n",
       "       [0.45654002],\n",
       "       [0.45654002],\n",
       "       [0.42671138],\n",
       "       [0.02087906],\n",
       "       [0.4223725 ],\n",
       "       [0.50633043],\n",
       "       [0.9908439 ],\n",
       "       [0.503905  ],\n",
       "       [0.46137813],\n",
       "       [0.22745557],\n",
       "       [0.9732425 ],\n",
       "       [0.36162752],\n",
       "       [0.88674015],\n",
       "       [0.503905  ],\n",
       "       [0.60008776],\n",
       "       [0.49388972],\n",
       "       [0.38364857],\n",
       "       [0.4647179 ],\n",
       "       [0.10597955],\n",
       "       [0.8153251 ],\n",
       "       [0.35727194],\n",
       "       [0.30541104],\n",
       "       [0.92627984],\n",
       "       [0.42671138],\n",
       "       [0.9248495 ],\n",
       "       [0.36162752],\n",
       "       [0.6420559 ],\n",
       "       [0.47458044],\n",
       "       [0.37618953],\n",
       "       [0.34400535],\n",
       "       [0.42195344],\n",
       "       [0.5657421 ],\n",
       "       [0.42671138],\n",
       "       [0.8293693 ],\n",
       "       [0.8153251 ],\n",
       "       [0.47657314],\n",
       "       [0.9248495 ],\n",
       "       [0.44874012],\n",
       "       [0.01453527],\n",
       "       [0.06089308],\n",
       "       [0.36162752],\n",
       "       [0.6789009 ],\n",
       "       [0.4527891 ],\n",
       "       [0.5156493 ],\n",
       "       [0.4791694 ],\n",
       "       [0.4365825 ],\n",
       "       [0.86725366],\n",
       "       [0.30541104],\n",
       "       [0.3500576 ],\n",
       "       [0.781942  ],\n",
       "       [0.44874012],\n",
       "       [0.42671138],\n",
       "       [0.98934025],\n",
       "       [0.4436247 ],\n",
       "       [0.19951774],\n",
       "       [0.8354886 ],\n",
       "       [0.9576781 ],\n",
       "       [0.60008776],\n",
       "       [0.88845396],\n",
       "       [0.431276  ],\n",
       "       [0.47458044],\n",
       "       [0.59331053],\n",
       "       [0.83230066],\n",
       "       [0.02087906],\n",
       "       [0.52525795],\n",
       "       [0.31670812],\n",
       "       [0.91964185],\n",
       "       [0.72473234],\n",
       "       [0.34871167],\n",
       "       [0.98241085],\n",
       "       [0.36162752],\n",
       "       [0.93811053],\n",
       "       [0.4647179 ],\n",
       "       [0.60008776],\n",
       "       [0.5724828 ],\n",
       "       [0.9425514 ],\n",
       "       [0.5460741 ],\n",
       "       [0.6774826 ],\n",
       "       [0.52827823],\n",
       "       [0.48873577],\n",
       "       [0.93003345],\n",
       "       [0.292508  ],\n",
       "       [0.42671138],\n",
       "       [0.2829273 ],\n",
       "       [0.91913944],\n",
       "       [0.25692263],\n",
       "       [0.977775  ],\n",
       "       [0.8153251 ],\n",
       "       [0.3778533 ],\n",
       "       [0.9425514 ],\n",
       "       [0.9590253 ],\n",
       "       [0.20421118],\n",
       "       [0.52827823],\n",
       "       [0.8592932 ],\n",
       "       [0.85036737],\n",
       "       [0.42671138],\n",
       "       [0.503905  ],\n",
       "       [0.3037184 ],\n",
       "       [0.8315427 ],\n",
       "       [0.9954566 ],\n",
       "       [0.42671138],\n",
       "       [0.47863322],\n",
       "       [0.47458044],\n",
       "       [0.42671138],\n",
       "       [0.7187437 ],\n",
       "       [0.49388972],\n",
       "       [0.7581669 ],\n",
       "       [0.33853534],\n",
       "       [0.48043343],\n",
       "       [0.30541104],\n",
       "       [0.06936032],\n",
       "       [0.44874012],\n",
       "       [0.52827823],\n",
       "       [0.99513286],\n",
       "       [0.1391305 ],\n",
       "       [0.47458044],\n",
       "       [0.82496816],\n",
       "       [0.22745557],\n",
       "       [0.503905  ],\n",
       "       [0.36162752],\n",
       "       [0.11979192],\n",
       "       [0.3877553 ],\n",
       "       [0.7539667 ],\n",
       "       [0.503905  ],\n",
       "       [0.4088377 ],\n",
       "       [0.42671138],\n",
       "       [0.9908439 ],\n",
       "       [0.36162752],\n",
       "       [0.03175789],\n",
       "       [0.40174815],\n",
       "       [0.35417023],\n",
       "       [0.42671138],\n",
       "       [0.9933971 ],\n",
       "       [0.14368497],\n",
       "       [0.0193373 ],\n",
       "       [0.45654002],\n",
       "       [0.45654002],\n",
       "       [0.4527891 ],\n",
       "       [0.60499334],\n",
       "       [0.10597955],\n",
       "       [0.8153251 ],\n",
       "       [0.30541104],\n",
       "       [0.44874012],\n",
       "       [0.431276  ],\n",
       "       [0.47458044],\n",
       "       [0.37618953],\n",
       "       [0.866654  ],\n",
       "       [0.42195344],\n",
       "       [0.4647179 ],\n",
       "       [0.08287226],\n",
       "       [0.46137813],\n",
       "       [0.09200818],\n",
       "       [0.9864179 ],\n",
       "       [0.03073802],\n",
       "       [0.98656   ],\n",
       "       [0.30541104],\n",
       "       [0.3500576 ],\n",
       "       [0.44874012],\n",
       "       [0.8491449 ],\n",
       "       [0.52525795],\n",
       "       [0.60008776],\n",
       "       [0.95901424],\n",
       "       [0.36162752],\n",
       "       [0.60008776],\n",
       "       [0.27634743],\n",
       "       [0.35417023],\n",
       "       [0.503905  ],\n",
       "       [0.52827823],\n",
       "       [0.9228321 ],\n",
       "       [0.01961827],\n",
       "       [0.93271136],\n",
       "       [0.07347297],\n",
       "       [0.42671138],\n",
       "       [0.25074238],\n",
       "       [0.6692606 ],\n",
       "       [0.55995405],\n",
       "       [0.80908895],\n",
       "       [0.35417023],\n",
       "       [0.81781995],\n",
       "       [0.50633043],\n",
       "       [0.90189457],\n",
       "       [0.3500576 ],\n",
       "       [0.29084727],\n",
       "       [0.6008972 ],\n",
       "       [0.14040062],\n",
       "       [0.04350957],\n",
       "       [0.49745756],\n",
       "       [0.30541104],\n",
       "       [0.44874012],\n",
       "       [0.9560679 ],\n",
       "       [0.42671138],\n",
       "       [0.5955499 ],\n",
       "       [0.45654002],\n",
       "       [0.45654002],\n",
       "       [0.1378791 ],\n",
       "       [0.60008776],\n",
       "       [0.49388972],\n",
       "       [0.7391631 ],\n",
       "       [0.35417023],\n",
       "       [0.5346993 ],\n",
       "       [0.33853534],\n",
       "       [0.9078411 ],\n",
       "       [0.87311536],\n",
       "       [0.55995405],\n",
       "       [0.2433051 ],\n",
       "       [0.64437246],\n",
       "       [0.35417023],\n",
       "       [0.54817945],\n",
       "       [0.72473234],\n",
       "       [0.05716418],\n",
       "       [0.42671138],\n",
       "       [0.90185523],\n",
       "       [0.5762879 ],\n",
       "       [0.5762879 ],\n",
       "       [0.5762879 ],\n",
       "       [0.5762879 ],\n",
       "       [0.5762879 ],\n",
       "       [0.5762879 ],\n",
       "       [0.5762879 ],\n",
       "       [0.5762879 ],\n",
       "       [0.5762879 ],\n",
       "       [0.5762879 ],\n",
       "       [0.5762879 ],\n",
       "       [0.5762879 ],\n",
       "       [0.5762879 ],\n",
       "       [0.5762879 ],\n",
       "       [0.5762879 ],\n",
       "       [0.5762879 ],\n",
       "       [0.5762879 ],\n",
       "       [0.5762879 ],\n",
       "       [0.5762879 ],\n",
       "       [0.5762879 ],\n",
       "       [0.5762879 ],\n",
       "       [0.5762879 ],\n",
       "       [0.5762879 ],\n",
       "       [0.5762879 ],\n",
       "       [0.5762879 ],\n",
       "       [0.5762879 ],\n",
       "       [0.5762879 ],\n",
       "       [0.5762879 ],\n",
       "       [0.5762879 ],\n",
       "       [0.5762879 ],\n",
       "       [0.5762879 ],\n",
       "       [0.5762879 ],\n",
       "       [0.5762879 ],\n",
       "       [0.5762879 ],\n",
       "       [0.5762879 ],\n",
       "       [0.5762879 ],\n",
       "       [0.5762879 ],\n",
       "       [0.5762879 ],\n",
       "       [0.5762879 ],\n",
       "       [0.5762879 ]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3fUqxDOYQG4q"
   },
   "source": [
    "We are able to predict the sentiment of the the given review with 81% Accuracy. "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Questions - Project 1 - Sequential Models in NLP - Sentiment Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
